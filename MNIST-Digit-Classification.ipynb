{"cells":[{"metadata":{"id":"3DR-eO17geWu"},"cell_type":"markdown","source":"# Convolutional Neural Network"},{"metadata":{"id":"EMefrVPCg-60"},"cell_type":"markdown","source":"### Importing the libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras import layers\nfrom keras.datasets import mnist\nfrom keras.utils import to_categorical\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, Flatten\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"id":"oxQxCBWyoGPE"},"cell_type":"markdown","source":"## Part 1 - Data Preprocessing"},{"metadata":{"id":"MvE-heJNo3GG"},"cell_type":"markdown","source":"### Preprocessing the Training set"},{"metadata":{"id":"F89QYx-c-fFq","tags":[],"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\ntraining_set = train_datagen.flow_from_directory(\n        '../input/mnistasjpg/trainingSet/trainingSet',\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"mrCMmGw9pHys"},"cell_type":"markdown","source":"### Preprocessing the Test set"},{"metadata":{"id":"PLRbZ0VSBLx_","tags":[],"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1./255)\ntest_set = test_datagen.flow_from_directory(\n        '../input/mnistasjpg/trainingSample/trainingSample',\n        target_size=(64, 64),\n        batch_size=32,\n        class_mode='categorical')\n","execution_count":null,"outputs":[]},{"metadata":{"id":"af8O4l90gk7B"},"cell_type":"markdown","source":"## Part 2 - Building the CNN"},{"metadata":{},"cell_type":"markdown","source":"### Initialising the CNN"},{"metadata":{"id":"wHDHJROSVq2L","trusted":true},"cell_type":"code","source":"cnn = keras.Sequential()","execution_count":null,"outputs":[]},{"metadata":{"id":"u5YJj_XMl5LF"},"cell_type":"markdown","source":"### Step 1 - Convolution"},{"metadata":{"id":"MaYk58UXWAYr","trusted":true},"cell_type":"code","source":"cnn.add(layers.Conv2D(32, (3, 3), (1, 1), padding='valid', input_shape=(64,64,3), name='conv2d_1_1'))\ncnn.add(layers.Conv2D(32, (3, 3), (1, 1), padding='same', name='conv2d_1_2'))","execution_count":null,"outputs":[]},{"metadata":{"id":"tf87FpvxmNOJ"},"cell_type":"markdown","source":"### Step 2 - Normalizing, Actiavtion, Pooling"},{"metadata":{"id":"RfycE-o9Y7vJ","trusted":true},"cell_type":"code","source":"cnn.add(layers.BatchNormalization(name='bn_1'))\ncnn.add(layers.Activation('relu', name='relu_1'))\ncnn.add(layers.MaxPooling2D((2, 2), (2, 2), padding='valid', name='mp2d_1'))\ncnn.add(layers.Dropout(0.2, name='drop_1'))","execution_count":null,"outputs":[]},{"metadata":{"id":"xaTOgD8rm4mU"},"cell_type":"markdown","source":"### Adding a second convolutional layer"},{"metadata":{"id":"x9WvtZXQXzWm","trusted":true},"cell_type":"code","source":"cnn.add(layers.Conv2D(64, (3, 3), (1, 1), padding='valid', name='conv2d_2_1'))\ncnn.add(layers.Conv2D(64, (3, 3), (1, 1), padding='same', name='conv2d_2_2'))\ncnn.add(layers.BatchNormalization(name='bn_2'))\ncnn.add(layers.Activation('relu', name='relu_2'))\ncnn.add(layers.MaxPooling2D((2, 2), (2, 2), padding='valid', name='mp2d_2'))\ncnn.add(layers.Dropout(0.2, name='drop_2'))","execution_count":null,"outputs":[]},{"metadata":{"id":"tmiEuvTunKfk"},"cell_type":"markdown","source":"### Step 3 - Flattening"},{"metadata":{"id":"_Gutjk0bZTbM","trusted":true},"cell_type":"code","source":"cnn.add(layers.Flatten())","execution_count":null,"outputs":[]},{"metadata":{"id":"dAoSECOm203v"},"cell_type":"markdown","source":"### Step 4 - Full Connection"},{"metadata":{"id":"CeY9EfqEaGNQ","trusted":true},"cell_type":"code","source":"cnn.add(layers.Dense(100, activation='relu'))","execution_count":null,"outputs":[]},{"metadata":{"id":"yTldFvbX28Na"},"cell_type":"markdown","source":"### Step 5 - Output Layer"},{"metadata":{"id":"WbKCiTxeazhY","trusted":true},"cell_type":"code","source":"cnn.add(layers.Dense(10, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"id":"D6XkI90snSDl"},"cell_type":"markdown","source":"## Part 3 - Training the CNN"},{"metadata":{"id":"vfrFQACEnc6i"},"cell_type":"markdown","source":"### Compiling the CNN"},{"metadata":{"id":"5xB9P5xrbti0","trusted":true},"cell_type":"code","source":"cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\ncnn.summary()","execution_count":null,"outputs":[]},{"metadata":{"id":"ehS-v3MIpX2h"},"cell_type":"markdown","source":"### Training the CNN on the Training set and evaluating it on the Test set"},{"metadata":{"id":"1sTtZmLrb3ag","tags":[],"trusted":true},"cell_type":"code","source":"cnn.fit(x = training_set, validation_data = test_set ,  epochs = 1)","execution_count":null,"outputs":[]},{"metadata":{"id":"U3PZasO0006Z"},"cell_type":"markdown","source":"## Part 4 - Making a single prediction"},{"metadata":{"id":"29FRfgFidthZ","trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras.preprocessing import image\ntest_image = image.load_img('../input/mnistasjpg/trainingSet/trainingSet/2/img_10027.jpg', target_size = (64,64))\ntest_image = image.img_to_array(test_image)\ntest_image = np.expand_dims(test_image, axis = 0)\nresult = cnn.predict(test_image)\ntraining_set.class_indices\nfor i in range(10):\n    if result[0][i] == 1:\n        prediction = i","execution_count":null,"outputs":[]},{"metadata":{"id":"bg1p97uchIB_","tags":[],"trusted":true},"cell_type":"code","source":"print(prediction)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}